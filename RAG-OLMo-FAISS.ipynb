{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RAG Demo with OLMo and ArXiv `astro-ph` Dataset"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RAG based approach below is a demonstration of how to use [OLMo-1B](https://huggingface.co/allenai/OLMo-1B) LLM model by AI2 to generate an abstract completion for a given input text. The input text is a random starting abstract from `astro-ph` category of [ArXiv Dataset](https://www.kaggle.com/datasets/Cornell-University/arxiv). The abstract completion is generated by the model using the RAG approach. The RAG approach retrieves relevant documents from [Qdrant Vector Database](https://qdrant.tech/), which provides contextual information to the model for generating the completion.\n",
    "\n",
    "The input text was retrieved from the [AstroLLaMa Paper](https://arxiv.org/abs/2309.06126). Rather than fine-tuning a model, we wanted to see if RAG approach can also work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following statement as user input:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T07:42:02.430832Z",
     "start_time": "2024-04-23T07:42:02.426493Z"
    }
   },
   "source": [
    "statement = \"\"\"The Magellanic Stream (MS) - an enormous ribbon of gas spanning 140âˆ˜ of the southern\n",
    "sky trailing the Magellanic Clouds - has been exquisitely mapped in the five decades since\n",
    "its discovery. However, despite concerted efforts, no stellar counterpart to the MS has been\n",
    "conclusively identified. This stellar stream would reveal the distance and 6D kinematics of\n",
    "the MS, constraining its formation and the past orbital history of the Clouds. We\"\"\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T07:42:02.747608Z",
     "start_time": "2024-04-23T07:42:02.465176Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import zipfile\n",
    "import json\n",
    "import pandas as pd\n",
    "import io\n",
    "import fsspec\n",
    "\n",
    "def fetch_arxiv_dataset(zip_url: str) -> pd.DataFrame:\n",
    "    cols = ['id', 'title', 'abstract', 'categories']\n",
    "\n",
    "    with fsspec.open(zip_url) as f:\n",
    "        with zipfile.ZipFile(f) as archive:\n",
    "            data = []\n",
    "            json_file = archive.filelist[0]\n",
    "            with archive.open(json_file) as f:\n",
    "                for line in io.TextIOWrapper(f, encoding=\"latin-1\"):\n",
    "                    doc = json.loads(line)\n",
    "                    lst = [doc['id'], doc['title'], doc['abstract'], doc['categories']]\n",
    "                    data.append(lst)\n",
    "                    \n",
    "            df_data = pd.DataFrame(data=data, columns=cols)\n",
    "    return df_data\n",
    "\n",
    "# https://github.com/allenai/open-instruct/blob/main/eval/templates.py\n",
    "def create_prompt_with_olmo_chat_format(messages, bos=\"|||IP_ADDRESS|||\", eos=\"|||IP_ADDRESS|||\", add_bos=True):\n",
    "    formatted_text = \"\"\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            formatted_text += \"<|system|>\\n\" + message[\"content\"] + \"\\n\"\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            formatted_text += \"<|user|>\\n\" + message[\"content\"] + \"\\n\"\n",
    "        elif message[\"role\"] == \"assistant\":\n",
    "            formatted_text += \"<|assistant|>\\n\" + message[\"content\"].strip() + eos + \"\\n\"\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Olmo chat template only supports 'system', 'user' and 'assistant' roles. Invalid role: {}.\".format(message[\"role\"])\n",
    "                )\n",
    "    formatted_text += \"<|assistant|>\\n\"\n",
    "    formatted_text = bos + formatted_text  # forcibly add bos\n",
    "    return formatted_text\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve documents (arXiv `astro-ph` abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section retrieves the arXiv abstracts and creates documents\n",
    "for loading into a vector database. You can skip running the following sections\n",
    "if you have a local copy of the Qdrant Vector Database data ready to go."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T07:42:02.895351Z",
     "start_time": "2024-04-23T07:42:02.748531Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders import DataFrameLoader"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T07:42:02.903801Z",
     "start_time": "2024-04-23T07:42:02.896275Z"
    }
   },
   "source": [
    "# zip_url = \"https://storage.googleapis.com/kaggle-data-sets/612177/7925852/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com/20240327/auto/storage/goog4_request&X-Goog-Date=20240327T183523Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=4747ce35edc693785c00b4ade2fc7f62149173bf160f1b04f97fc6a752bfb1ccb5408359a16b475e7d955f04a52f2fb9f916d8090330993839fabfb1835847e0c62452243ecc74e232eeed1d747beaf6da1209b9614d305c020e6bd09bb096e6c6e2bb4711d96fb457ed1533c04bb78690253d3b6f4a4068aa3b9cd073742a3ed68562fa2a88a29e646a629dee0a26f99ff0539b5f81c926bc2b5a62642ac9f0a92febc7ca812a61351191334baad93b3ecca2ac408da8ca35a4d6e8afda67d6e8196b50c20ee18358a19cb21c25dfbcc7394bc99b280ed9222c8a933ea91f7d4b65aba05156ab985b36e761a70a35f6bbd208b9507a04ff68e15c258ec5920f\"\n",
    "zip_url = \"./archive.zip\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T07:42:36.705786Z",
     "start_time": "2024-04-23T07:42:02.904823Z"
    }
   },
   "source": [
    "# Fetch the dataset containing all arXiv abstracts\n",
    "df_data = fetch_arxiv_dataset(zip_url)\n",
    "# Filter the dataset to only include astro-ph category\n",
    "astro_df = df_data[df_data.categories.str.contains('astro-ph')].reset_index(drop=True)\n",
    "print(\"Number of astro-ph papers: \", len(astro_df))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of astro-ph papers:  338991\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Use subset of 10000 documents for creating Index/DB\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T07:42:36.720774Z",
     "start_time": "2024-04-23T07:42:36.706586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "astro_df = astro_df[:100]\n",
    "astro_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           id                                              title  \\\n",
       "0   0704.0009  The Spitzer c2d Survey of Large, Nearby, Inste...   \n",
       "1   0704.0017  Spectroscopic Observations of the Intermediate...   \n",
       "2   0704.0023  ALMA as the ideal probe of the solar chromosphere   \n",
       "3   0704.0044  Astrophysical gyrokinetics: kinetic and fluid ...   \n",
       "4   0704.0048  Inference on white dwarf binary systems using ...   \n",
       "..        ...                                                ...   \n",
       "95  0704.0486  Kinematic Decoupling of Globular Clusters with...   \n",
       "96  0704.0490  Long Distance Signaling Using Axion-like Parti...   \n",
       "97  0704.0510  Axino warm dark matter and $\\Omega_b - \\Omega_...   \n",
       "98  0704.0513  SDSS J233325.92+152222.1 and the evolution of ...   \n",
       "99  0704.0518  Dust and gas emission in the prototypical hot ...   \n",
       "\n",
       "                                             abstract  \\\n",
       "0     We discuss the results from the combined IRA...   \n",
       "1     Results from spectroscopic observations of t...   \n",
       "2     The very nature of the solar chromosphere, i...   \n",
       "3     We present a theoretical framework for plasm...   \n",
       "4     We report on the analysis of selected single...   \n",
       "..                                                ...   \n",
       "95    About 25% of the Milky Way globular clusters...   \n",
       "96    The possible existence of axion-like particl...   \n",
       "97    We show that axinos, which are dominantly ge...   \n",
       "98    Intermediate polars (IPs) are cataclysmic va...   \n",
       "99    Aiming at a better understand of the physica...   \n",
       "\n",
       "                                           categories  \n",
       "0                                            astro-ph  \n",
       "1                                            astro-ph  \n",
       "2                                            astro-ph  \n",
       "3   astro-ph nlin.CD physics.plasm-ph physics.spac...  \n",
       "4                                      gr-qc astro-ph  \n",
       "..                                                ...  \n",
       "95                                           astro-ph  \n",
       "96                             hep-ph astro-ph hep-th  \n",
       "97                                    hep-ph astro-ph  \n",
       "98                                           astro-ph  \n",
       "99                                           astro-ph  \n",
       "\n",
       "[100 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0009</td>\n",
       "      <td>The Spitzer c2d Survey of Large, Nearby, Inste...</td>\n",
       "      <td>We discuss the results from the combined IRA...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0017</td>\n",
       "      <td>Spectroscopic Observations of the Intermediate...</td>\n",
       "      <td>Results from spectroscopic observations of t...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0023</td>\n",
       "      <td>ALMA as the ideal probe of the solar chromosphere</td>\n",
       "      <td>The very nature of the solar chromosphere, i...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0044</td>\n",
       "      <td>Astrophysical gyrokinetics: kinetic and fluid ...</td>\n",
       "      <td>We present a theoretical framework for plasm...</td>\n",
       "      <td>astro-ph nlin.CD physics.plasm-ph physics.spac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0048</td>\n",
       "      <td>Inference on white dwarf binary systems using ...</td>\n",
       "      <td>We report on the analysis of selected single...</td>\n",
       "      <td>gr-qc astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0704.0486</td>\n",
       "      <td>Kinematic Decoupling of Globular Clusters with...</td>\n",
       "      <td>About 25% of the Milky Way globular clusters...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0704.0490</td>\n",
       "      <td>Long Distance Signaling Using Axion-like Parti...</td>\n",
       "      <td>The possible existence of axion-like particl...</td>\n",
       "      <td>hep-ph astro-ph hep-th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0704.0510</td>\n",
       "      <td>Axino warm dark matter and $\\Omega_b - \\Omega_...</td>\n",
       "      <td>We show that axinos, which are dominantly ge...</td>\n",
       "      <td>hep-ph astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0704.0513</td>\n",
       "      <td>SDSS J233325.92+152222.1 and the evolution of ...</td>\n",
       "      <td>Intermediate polars (IPs) are cataclysmic va...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0704.0518</td>\n",
       "      <td>Dust and gas emission in the prototypical hot ...</td>\n",
       "      <td>Aiming at a better understand of the physica...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T07:42:36.723243Z",
     "start_time": "2024-04-23T07:42:36.721519Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T07:42:36.736227Z",
     "start_time": "2024-04-23T07:42:36.723876Z"
    }
   },
   "source": [
    "# Eargerly load the dataframe full of abstracts\n",
    "# to memory in the form of langchain Document objects\n",
    "loader = DataFrameLoader(astro_df, page_content_column=\"abstract\")\n",
    "\n",
    "documents = loader.load() "
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Document Embeddings to Qdrant/FAISS Vector Database"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T09:00:03.243878Z",
     "start_time": "2024-04-23T09:00:03.219709Z"
    }
   },
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Setup Vector DB"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T09:00:05.911535Z",
     "start_time": "2024-04-23T09:00:04.568842Z"
    }
   },
   "source": [
    "# Setup the embedding, we are using the MiniLM model here\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T09:00:09.071522Z",
     "start_time": "2024-04-23T09:00:06.439068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "start_time = time.time()\n",
    "faiss = FAISS.from_documents(documents, embedding)\n",
    "print(f\"Total time = {time.time() - start_time}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating text enbeddings took 2.5943782329559326 seconds\n",
      "Using FAISS IndexHNSWFlat with parameters d=384 m=32\n",
      "Creating Vectorstore took 0.003511667251586914 seconds\n",
      "Total time = 2.605375051498413\n",
      "CPU times: user 16.3 s, sys: 4.9 s, total: 21.2 s\n",
      "Wall time: 2.61 s\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T09:00:09.992639Z",
     "start_time": "2024-04-23T09:00:09.970012Z"
    }
   },
   "cell_type": "code",
   "source": "faiss.save_local(\"faiss_index\")",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T09:05:23.644879Z",
     "start_time": "2024-04-23T09:05:23.616566Z"
    }
   },
   "cell_type": "code",
   "source": "# new_faiss = FAISS.load_local(\"./faiss_index\", embedding, allow_dangerous_deserialization=True)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x7f5998c36310>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Test out the FAISS collection"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:02:15.594378Z",
     "start_time": "2024-04-23T08:02:15.570609Z"
    }
   },
   "cell_type": "code",
   "source": "retriever = faiss.as_retriever(search_kwargs={\"k\": 5})",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:02:16.598564Z",
     "start_time": "2024-04-23T08:02:16.572624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "search_queries = [\n",
    "    \"What time is it\",\n",
    "    \"What to watch\",\n",
    "    \"What time is it\",\n",
    "    \"What is my IP\",\n",
    "    \"How many weeks in a year\",\n",
    "    \"How many ounces in a cup\",\n",
    "    \"How many days until Christmas\",\n",
    "    \"When is the Super Bowl\",\n",
    "    \"How to screenshot on Mac\",\n",
    "    \"Who called me from this phone number\",\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:05:16.642461Z",
     "start_time": "2024-04-23T08:04:09.635202Z"
    }
   },
   "source": [
    "%%time\n",
    "for _i in range(1000):\n",
    "    for query in search_queries:\n",
    "        found_docs = retriever.get_relevant_documents(query)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 18s, sys: 25.7 s, total: 3min 44s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "print(format_docs(found_docs))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup OLMo Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_name = \"allenai/OLMo-1B\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# # Download the model and its configuration file locally\n",
    "# # from the Hugging Face Hub\n",
    "# # we will only download the configuration file and the model as safetensors file\n",
    "# local_dir = Path(\"./OLMo-1B\")\n",
    "# model_path = snapshot_download(\n",
    "#     repo_id=model_name,\n",
    "#     ignore_patterns=[\"*.bin\"],\n",
    "#     local_dir=local_dir,\n",
    "#     local_dir_use_symlinks=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_path = Path(\"./OLMo-1B\")\n",
    "olmo = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    local_files_only=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Setup the text generation pipeline with the OLMo model\n",
    "olmo_pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=olmo,\n",
    "    tokenizer=tokenizer,\n",
    "    temperature=0.2,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=400,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the langchain pipeline for the OLMo model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain.llms import HuggingFacePipeline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "llm = HuggingFacePipeline(pipeline=olmo_pipe)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the system prompts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain.prompts import PromptTemplate"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "no_context_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=create_prompt_with_olmo_chat_format(messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an astrophysics expert. Finish the given statement.\"}, \n",
    "        {\"role\": \"user\", \"content\": \"{question}\"}\n",
    "    ]),\n",
    ")\n",
    "\n",
    "with_context_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=create_prompt_with_olmo_chat_format(messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an astrophysics expert. Use the following pieces of retrieved context to finish the given statement:\\n{context}\"}, \n",
    "        {\"role\": \"user\", \"content\": \"{question}\"}\n",
    "    ]),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the chain of processes for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "llm_chain = llm | StrOutputParser()\n",
    "no_context_chain = {\"question\": RunnablePassthrough()} | no_context_prompt | llm_chain\n",
    "rag_chain = {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} | with_context_prompt | llm_chain"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the no-context pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "no_context_answer = no_context_chain.invoke(statement)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(no_context_answer)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rag_answer = rag_chain.invoke(statement)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "print(rag_answer)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "faiss.save_local(\"faiss_index\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "faiss_local = FAISS.load_local(\"faiss_index\", embedding, allow_dangerous_deserialization=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "faiss_local = faiss_local.vectors",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "retriever = faiss_local.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# Test out the statement retrieval\n",
    "found_docs = retriever.get_relevant_documents(statement)\n",
    "print(format_docs(found_docs))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssec-scipy2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
