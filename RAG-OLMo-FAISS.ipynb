{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RAG Demo with OLMo and ArXiv `astro-ph` Dataset"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RAG based approach below is a demonstration of how to use [OLMo-1B](https://huggingface.co/allenai/OLMo-1B) LLM model by AI2 to generate an abstract completion for a given input text. The input text is a random starting abstract from `astro-ph` category of [ArXiv Dataset](https://www.kaggle.com/datasets/Cornell-University/arxiv). The abstract completion is generated by the model using the RAG approach. The RAG approach retrieves relevant documents from [Qdrant Vector Database](https://qdrant.tech/), which provides contextual information to the model for generating the completion.\n",
    "\n",
    "The input text was retrieved from the [AstroLLaMa Paper](https://arxiv.org/abs/2309.06126). Rather than fine-tuning a model, we wanted to see if RAG approach can also work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following statement as user input:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:06:41.329252Z",
     "start_time": "2024-04-22T04:06:41.325642Z"
    }
   },
   "source": [
    "statement = \"\"\"The Magellanic Stream (MS) - an enormous ribbon of gas spanning 140âˆ˜ of the southern\n",
    "sky trailing the Magellanic Clouds - has been exquisitely mapped in the five decades since\n",
    "its discovery. However, despite concerted efforts, no stellar counterpart to the MS has been\n",
    "conclusively identified. This stellar stream would reveal the distance and 6D kinematics of\n",
    "the MS, constraining its formation and the past orbital history of the Clouds. We\"\"\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:06:41.653772Z",
     "start_time": "2024-04-22T04:06:41.378519Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import zipfile\n",
    "import json\n",
    "import pandas as pd\n",
    "import io\n",
    "import fsspec\n",
    "\n",
    "def fetch_arxiv_dataset(zip_url: str) -> pd.DataFrame:\n",
    "    cols = ['id', 'title', 'abstract', 'categories']\n",
    "\n",
    "    with fsspec.open(zip_url) as f:\n",
    "        with zipfile.ZipFile(f) as archive:\n",
    "            data = []\n",
    "            json_file = archive.filelist[0]\n",
    "            with archive.open(json_file) as f:\n",
    "                for line in io.TextIOWrapper(f, encoding=\"latin-1\"):\n",
    "                    doc = json.loads(line)\n",
    "                    lst = [doc['id'], doc['title'], doc['abstract'], doc['categories']]\n",
    "                    data.append(lst)\n",
    "                    \n",
    "            df_data = pd.DataFrame(data=data, columns=cols)\n",
    "    return df_data\n",
    "\n",
    "# https://github.com/allenai/open-instruct/blob/main/eval/templates.py\n",
    "def create_prompt_with_olmo_chat_format(messages, bos=\"|||IP_ADDRESS|||\", eos=\"|||IP_ADDRESS|||\", add_bos=True):\n",
    "    formatted_text = \"\"\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            formatted_text += \"<|system|>\\n\" + message[\"content\"] + \"\\n\"\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            formatted_text += \"<|user|>\\n\" + message[\"content\"] + \"\\n\"\n",
    "        elif message[\"role\"] == \"assistant\":\n",
    "            formatted_text += \"<|assistant|>\\n\" + message[\"content\"].strip() + eos + \"\\n\"\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Olmo chat template only supports 'system', 'user' and 'assistant' roles. Invalid role: {}.\".format(message[\"role\"])\n",
    "                )\n",
    "    formatted_text += \"<|assistant|>\\n\"\n",
    "    formatted_text = bos + formatted_text  # forcibly add bos\n",
    "    return formatted_text\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve documents (arXiv `astro-ph` abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section retrieves the arXiv abstracts and creates documents\n",
    "for loading into a vector database. You can skip running the following sections\n",
    "if you have a local copy of the Qdrant Vector Database data ready to go."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:06:41.817088Z",
     "start_time": "2024-04-22T04:06:41.655066Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders import DataFrameLoader"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:06:41.825442Z",
     "start_time": "2024-04-22T04:06:41.817882Z"
    }
   },
   "source": [
    "# zip_url = \"https://storage.googleapis.com/kaggle-data-sets/612177/7925852/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com/20240327/auto/storage/goog4_request&X-Goog-Date=20240327T183523Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=4747ce35edc693785c00b4ade2fc7f62149173bf160f1b04f97fc6a752bfb1ccb5408359a16b475e7d955f04a52f2fb9f916d8090330993839fabfb1835847e0c62452243ecc74e232eeed1d747beaf6da1209b9614d305c020e6bd09bb096e6c6e2bb4711d96fb457ed1533c04bb78690253d3b6f4a4068aa3b9cd073742a3ed68562fa2a88a29e646a629dee0a26f99ff0539b5f81c926bc2b5a62642ac9f0a92febc7ca812a61351191334baad93b3ecca2ac408da8ca35a4d6e8afda67d6e8196b50c20ee18358a19cb21c25dfbcc7394bc99b280ed9222c8a933ea91f7d4b65aba05156ab985b36e761a70a35f6bbd208b9507a04ff68e15c258ec5920f\"\n",
    "zip_url = \"./archive.zip\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:07:15.259435Z",
     "start_time": "2024-04-22T04:06:41.826442Z"
    }
   },
   "source": [
    "# Fetch the dataset containing all arXiv abstracts\n",
    "df_data = fetch_arxiv_dataset(zip_url)\n",
    "# Filter the dataset to only include astro-ph category\n",
    "astro_df = df_data[df_data.categories.str.contains('astro-ph')].reset_index(drop=True)\n",
    "print(\"Number of astro-ph papers: \", len(astro_df))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of astro-ph papers:  338991\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:07:15.274108Z",
     "start_time": "2024-04-22T04:07:15.260592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "astro_df = astro_df[:10000]\n",
    "print(\"Limited Set of of astro-ph papers: \", len(astro_df))\n",
    "astro_df"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limited Set of of astro-ph papers:  10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "             id                                              title  \\\n",
       "0     0704.0009  The Spitzer c2d Survey of Large, Nearby, Inste...   \n",
       "1     0704.0017  Spectroscopic Observations of the Intermediate...   \n",
       "2     0704.0023  ALMA as the ideal probe of the solar chromosphere   \n",
       "3     0704.0044  Astrophysical gyrokinetics: kinetic and fluid ...   \n",
       "4     0704.0048  Inference on white dwarf binary systems using ...   \n",
       "...         ...                                                ...   \n",
       "9995  0802.1531  Vacuum Energy, the Cosmological Constant and C...   \n",
       "9996  0802.1532  Cosmic dynamics in the era of Extremely Large ...   \n",
       "9997  0802.1533  Magnetic Fields in the Aftermath of Phase Tran...   \n",
       "9998  0802.1537  Nonthermal Synchrotron and Synchrotron Self-Co...   \n",
       "9999  0802.1538  The Intergalactic Propagation of Ultra-High En...   \n",
       "\n",
       "                                               abstract  \\\n",
       "0       We discuss the results from the combined IRA...   \n",
       "1       Results from spectroscopic observations of t...   \n",
       "2       The very nature of the solar chromosphere, i...   \n",
       "3       We present a theoretical framework for plasm...   \n",
       "4       We report on the analysis of selected single...   \n",
       "...                                                 ...   \n",
       "9995    We consider a universe with a compact extra ...   \n",
       "9996    The redshifts of all cosmologically distant ...   \n",
       "9997    The COSLAB effort has focussed on the format...   \n",
       "9998    Results of a leptonic jet model for the prom...   \n",
       "9999    It is likely that ultra-high energy cosmic r...   \n",
       "\n",
       "                                             categories  \n",
       "0                                              astro-ph  \n",
       "1                                              astro-ph  \n",
       "2                                              astro-ph  \n",
       "3     astro-ph nlin.CD physics.plasm-ph physics.spac...  \n",
       "4                                        gr-qc astro-ph  \n",
       "...                                                 ...  \n",
       "9995                       astro-ph gr-qc hep-ph hep-th  \n",
       "9996                                           astro-ph  \n",
       "9997              astro-ph cond-mat.other hep-ph hep-th  \n",
       "9998                                           astro-ph  \n",
       "9999                                    astro-ph hep-ph  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0009</td>\n",
       "      <td>The Spitzer c2d Survey of Large, Nearby, Inste...</td>\n",
       "      <td>We discuss the results from the combined IRA...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0017</td>\n",
       "      <td>Spectroscopic Observations of the Intermediate...</td>\n",
       "      <td>Results from spectroscopic observations of t...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0023</td>\n",
       "      <td>ALMA as the ideal probe of the solar chromosphere</td>\n",
       "      <td>The very nature of the solar chromosphere, i...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0044</td>\n",
       "      <td>Astrophysical gyrokinetics: kinetic and fluid ...</td>\n",
       "      <td>We present a theoretical framework for plasm...</td>\n",
       "      <td>astro-ph nlin.CD physics.plasm-ph physics.spac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0048</td>\n",
       "      <td>Inference on white dwarf binary systems using ...</td>\n",
       "      <td>We report on the analysis of selected single...</td>\n",
       "      <td>gr-qc astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0802.1531</td>\n",
       "      <td>Vacuum Energy, the Cosmological Constant and C...</td>\n",
       "      <td>We consider a universe with a compact extra ...</td>\n",
       "      <td>astro-ph gr-qc hep-ph hep-th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0802.1532</td>\n",
       "      <td>Cosmic dynamics in the era of Extremely Large ...</td>\n",
       "      <td>The redshifts of all cosmologically distant ...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0802.1533</td>\n",
       "      <td>Magnetic Fields in the Aftermath of Phase Tran...</td>\n",
       "      <td>The COSLAB effort has focussed on the format...</td>\n",
       "      <td>astro-ph cond-mat.other hep-ph hep-th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0802.1537</td>\n",
       "      <td>Nonthermal Synchrotron and Synchrotron Self-Co...</td>\n",
       "      <td>Results of a leptonic jet model for the prom...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0802.1538</td>\n",
       "      <td>The Intergalactic Propagation of Ultra-High En...</td>\n",
       "      <td>It is likely that ultra-high energy cosmic r...</td>\n",
       "      <td>astro-ph hep-ph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:07:15.637344Z",
     "start_time": "2024-04-22T04:07:15.274872Z"
    }
   },
   "source": [
    "# Eargerly load the dataframe full of abstracts\n",
    "# to memory in the form of langchain Document objects\n",
    "loader = DataFrameLoader(astro_df, page_content_column=\"abstract\")\n",
    "all_docs = loader.load()"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:07:15.640277Z",
     "start_time": "2024-04-22T04:07:15.638533Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Document Embeddings to Qdrant/FAISS Vector Database"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:07:15.657671Z",
     "start_time": "2024-04-22T04:07:15.640995Z"
    }
   },
   "source": [
    "from langchain_community.vectorstores import Qdrant, FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:07:15.668562Z",
     "start_time": "2024-04-22T04:07:15.658402Z"
    }
   },
   "source": [
    "import os"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:07:18.962230Z",
     "start_time": "2024-04-22T04:07:15.669884Z"
    }
   },
   "source": [
    "# Setup the embedding, we are using the MiniLM model here\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:13:30.076584Z",
     "start_time": "2024-04-22T04:07:18.962946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "documents = all_docs\n",
    "faiss = FAISS.from_documents(documents, embedding)\n",
    "# Over 10000 documents"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from_texts Embeddings creation took 370.8564827442169 seconds\n",
      "Inside FAISS __from\n",
      "Creating Vectorstore took 0.21229004859924316 seconds\n",
      "CPU times: user 42min 6s, sys: 10min 34s, total: 52min 41s\n",
      "Wall time: 6min 11s\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:13:30.094901Z",
     "start_time": "2024-04-22T04:13:30.077234Z"
    }
   },
   "source": [
    "# %%time\n",
    "# qdrant_path=\"./qdrant_data\"\n",
    "# qdrant_collection=\"arxiv_astro-ph_abstracts\"\n",
    "# \n",
    "# print(f\"Loading existing Qdrant collection '{qdrant_collection}'\")\n",
    "# from qdrant_client import QdrantClient\n",
    "# # If the Qdrant Vector Database Collection already exists, load it\n",
    "# client = QdrantClient(path=qdrant_path)\n",
    "# qdrant = Qdrant(\n",
    "#     client=client,\n",
    "#     collection_name=qdrant_collection,\n",
    "#     embeddings=embedding\n",
    "# )\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:13:30.097620Z",
     "start_time": "2024-04-22T04:13:30.095548Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:13:30.129743Z",
     "start_time": "2024-04-22T04:13:30.098578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%time\n",
    "# \n",
    "# documents = all_docs[:10000]\n",
    "# \n",
    "# # docker run -p 6333:6333 -v $(pwd)/path/to/data:/qdrant/storage qdrant/qdrant\n",
    "# qdrant_path=\"./qdrant_data_v2\"\n",
    "# qdrant_collection=\"arxiv_astro-ph_abstracts\"\n",
    "# \n",
    "# print(f\"Creating new Qdrant collection '{qdrant_collection}' from {len(documents)} documents\")\n",
    "# \n",
    "# # Load the documents into a Qdrant Vector Database Collection\n",
    "# # this will save locally in the current directory as sqlite\n",
    "# qdrant = Qdrant.from_documents(\n",
    "#     documents,\n",
    "#     embedding,\n",
    "#     path=qdrant_path,\n",
    "#     collection_name=qdrant_collection,\n",
    "# )\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test out the Qdrant collection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:13:30.157902Z",
     "start_time": "2024-04-22T04:13:30.130715Z"
    }
   },
   "source": [
    "# # Setup the retriever for later step\n",
    "# retriever = qdrant.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:13:30.178153Z",
     "start_time": "2024-04-22T04:13:30.158786Z"
    }
   },
   "cell_type": "code",
   "source": "retriever = faiss.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T04:13:50.645540Z",
     "start_time": "2024-04-22T04:13:30.179059Z"
    }
   },
   "source": [
    "%%time\n",
    "# Test out the statement retrieval\n",
    "for _i in range(1000):\n",
    "    found_docs = retriever.get_relevant_documents(statement)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 35s, sys: 7.3 s, total: 1min 43s\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(format_docs(found_docs))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup OLMo Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_name = \"allenai/OLMo-1B\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# # Download the model and its configuration file locally\n",
    "# # from the Hugging Face Hub\n",
    "# # we will only download the configuration file and the model as safetensors file\n",
    "# local_dir = Path(\"./OLMo-1B\")\n",
    "# model_path = snapshot_download(\n",
    "#     repo_id=model_name,\n",
    "#     ignore_patterns=[\"*.bin\"],\n",
    "#     local_dir=local_dir,\n",
    "#     local_dir_use_symlinks=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_path = Path(\"./OLMo-1B\")\n",
    "olmo = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    local_files_only=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Setup the text generation pipeline with the OLMo model\n",
    "olmo_pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=olmo,\n",
    "    tokenizer=tokenizer,\n",
    "    temperature=0.2,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=400,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the langchain pipeline for the OLMo model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain.llms import HuggingFacePipeline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "llm = HuggingFacePipeline(pipeline=olmo_pipe)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the system prompts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain.prompts import PromptTemplate"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "no_context_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=create_prompt_with_olmo_chat_format(messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an astrophysics expert. Finish the given statement.\"}, \n",
    "        {\"role\": \"user\", \"content\": \"{question}\"}\n",
    "    ]),\n",
    ")\n",
    "\n",
    "with_context_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=create_prompt_with_olmo_chat_format(messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an astrophysics expert. Use the following pieces of retrieved context to finish the given statement:\\n{context}\"}, \n",
    "        {\"role\": \"user\", \"content\": \"{question}\"}\n",
    "    ]),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the chain of processes for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "llm_chain = llm | StrOutputParser()\n",
    "no_context_chain = {\"question\": RunnablePassthrough()} | no_context_prompt | llm_chain\n",
    "rag_chain = {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} | with_context_prompt | llm_chain"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the no-context pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "no_context_answer = no_context_chain.invoke(statement)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(no_context_answer)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rag_answer = rag_chain.invoke(statement)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "print(rag_answer)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "faiss.save_local(\"faiss_index\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "faiss_local = FAISS.load_local(\"faiss_index\", embedding, allow_dangerous_deserialization=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "faiss_local = faiss_local.vectors",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "retriever = faiss_local.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# Test out the statement retrieval\n",
    "found_docs = retriever.get_relevant_documents(statement)\n",
    "print(format_docs(found_docs))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssec-scipy2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
